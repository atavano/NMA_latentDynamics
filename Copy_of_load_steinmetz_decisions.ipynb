{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michele1993/NMA_latentDynamics/blob/Michele/Copy_of_load_steinmetz_decisions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "VP6kxQOctEVi"
      },
      "source": [
        "## Loading of Steinmetz data\n",
        "\n",
        "includes some visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "execution": {},
        "id": "2y4FhdsKtEVl"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "execution": {},
        "id": "3CLTFvWXtEVm"
      },
      "outputs": [],
      "source": [
        "# @title Figure settings\n",
        "from matplotlib import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] = 15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "execution": {},
        "id": "cUkuF8JwtEVn"
      },
      "outputs": [],
      "source": [
        "# @title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = []\n",
        "for j in range(3):\n",
        "  fname.append('steinmetz_part%d.npz'%j)\n",
        "url = [\"https://osf.io/agvxh/download\"]\n",
        "url.append(\"https://osf.io/uv3mw/download\")\n",
        "url.append(\"https://osf.io/ehmw2/download\")\n",
        "\n",
        "for j in range(len(url)):\n",
        "  if not os.path.isfile(fname[j]):\n",
        "    try:\n",
        "      r = requests.get(url[j])\n",
        "    except requests.ConnectionError:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      if r.status_code != requests.codes.ok:\n",
        "        print(\"!!! Failed to download data !!!\")\n",
        "      else:\n",
        "        with open(fname[j], \"wb\") as fid:\n",
        "          fid.write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "execution": {},
        "id": "SY1EeN7rtEVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d3fc75-4b43-4187-99e9-1e441ecf75e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skipping\n"
          ]
        }
      ],
      "source": [
        "# REMOVE line below first time you run the colab \n",
        "%%script echo skipping \n",
        "\n",
        "# @title Data loading\n",
        "alldat = np.array([])\n",
        "for j in range(len(fname)):\n",
        "  alldat = np.hstack((alldat,\n",
        "                      np.load('steinmetz_part%d.npz'%j,\n",
        "                              allow_pickle=True)['dat']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Wb3bjxS0tEVo"
      },
      "source": [
        "`alldat` contains 39 sessions from 10 mice, data from Steinmetz et al, 2019. Time bins for all measurements are 10ms, starting 500ms before stimulus onset. The mouse had to determine which side has the highest contrast. For each `dat = alldat[k]`, you have the fields below. For extra variables, check out the extra notebook and extra data files (lfp, waveforms and exact spike times, non-binned). \n",
        "\n",
        "* `dat['mouse_name']`: mouse name\n",
        "* `dat['date_exp']`: when a session was performed\n",
        "* `dat['spks']`: neurons by trials by time bins.    \n",
        "* `dat['brain_area']`: brain area for each neuron recorded. \n",
        "* `dat['ccf']`: Allen Institute brain atlas coordinates for each neuron. \n",
        "* `dat['ccf_axes']`: axes names for the Allen CCF. \n",
        "* `dat['contrast_right']`: contrast level for the right stimulus, which is always contralateral to the recorded brain areas.\n",
        "* `dat['contrast_left']`: contrast level for left stimulus. \n",
        "* `dat['gocue']`: when the go cue sound was played. \n",
        "* `dat['response_time']`: when the response was registered, which has to be after the go cue. The mouse can turn the wheel before the go cue (and nearly always does!), but the stimulus on the screen won't move before the go cue.  \n",
        "* `dat['response']`: which side the response was (`-1`, `0`, `1`). When the right-side stimulus had higher contrast, the correct choice was `-1`. `0` is a no go response. \n",
        "* `dat['feedback_time']`: when feedback was provided. \n",
        "* `dat['feedback_type']`: if the feedback was positive (`+1`, reward) or negative (`-1`, white noise burst).  \n",
        "* `dat['wheel']`: turning speed of the wheel that the mice uses to make a response, sampled at `10ms`. \n",
        "* `dat['pupil']`: pupil area  (noisy, because pupil is very small) + pupil horizontal and vertical position.\n",
        "* `dat['face']`: average face motion energy from a video camera. \n",
        "* `dat['licks']`: lick detections, 0 or 1.   \n",
        "* `dat['trough_to_peak']`: measures the width of the action potential waveform for each neuron. Widths `<=10` samples are \"putative fast spiking neurons\". \n",
        "* `dat['%X%_passive']`: same as above for `X` = {`spks`, `pupil`, `wheel`, `contrast_left`, `contrast_right`} but for  passive trials at the end of the recording when the mouse was no longer engaged and stopped making responses. \n",
        "* `dat['prev_reward']`: time of the feedback (reward/white noise) on the previous trial in relation to the current stimulus time. \n",
        "* `dat['reaction_time']`: ntrials by 2. First column: reaction time computed from the wheel movement as the first sample above `5` ticks/10ms bin. Second column: direction of the wheel movement (`0` = no move detected).  \n",
        "\n",
        "\n",
        "The original dataset is here: https://figshare.com/articles/dataset/Dataset_from_Steinmetz_et_al_2019/9598406"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ============ **Data organisation** =============="
      ],
      "metadata": {
        "id": "k55odsXWA24A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key: the data are organised in spike counts x time bin"
      ],
      "metadata": {
        "id": "mRrPBebjQjKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define some useful methods:"
      ],
      "metadata": {
        "id": "x_MJF3HqMyDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_org(alldat,session_id = 11, ROI_number = 0): # e.g. ROI_number = 0:\"vis ctx\", 1:\"thal\", etc.\n",
        "\n",
        "  assert 0 <= session_id <= 38, 'session_id is out of range, it should be between 0 and 38'\n",
        "\n",
        "  brain_groups = [[\"VISa\", \"VISam\", \"VISl\", \"VISp\", \"VISpm\", \"VISrl\"],  # visual cortex, ROI_number = 0\n",
        "                [\"CL\", \"LD\", \"LGd\", \"LH\", \"LP\", \"MD\", \"MG\", \"PO\", \"POL\", \"PT\", \"RT\", \"SPF\", \"TH\", \"VAL\", \"VPL\", \"VPM\"], # thalamus, ROI_number = 1\n",
        "                [\"CA\", \"CA1\", \"CA2\", \"CA3\", \"DG\", \"SUB\", \"POST\"],  # hippocampal, ROI_number = 2\n",
        "                [\"ACA\", \"AUD\", \"COA\", \"DP\", \"ILA\", \"MOp\", \"MOs\", \"OLF\", \"ORB\", \"ORBm\", \"PIR\", \"PL\", \"SSp\", \"SSs\", \"RSP\",\"TT\"],  # non-visual cortex, ROI_number = 3\n",
        "                [\"APN\", \"IC\", \"MB\", \"MRN\", \"NB\", \"PAG\", \"RN\", \"SCs\", \"SCm\", \"SCig\", \"SCsg\", \"ZI\"],  # midbrain, ROI_number = 4\n",
        "                [\"ACB\", \"CP\", \"GPe\", \"LS\", \"LSc\", \"LSr\", \"MS\", \"OT\", \"SNr\", \"SI\"],  # basal ganglia, ROI_number = 5\n",
        "                [\"BLA\", \"BMA\", \"EP\", \"EPd\", \"MEA\"]  # cortical subplate, ROI_number = 6\n",
        "                ]\n",
        " \n",
        "  dat = alldat[session_id]\n",
        "  \n",
        "  ROI_nn = []\n",
        "  nn_per_area = [] # store the number of neurons in each sub area of a \"macro area\" for indexing\n",
        "  \n",
        "  ROI = brain_groups[ROI_number]\n",
        "\n",
        "  nn_per_area = dict()\n",
        "\n",
        "  indx_counter = 0\n",
        "  \n",
        "  # Extract spikes from ROI:\n",
        "  for r in ROI:\n",
        "    roi_nn = dat['spks'][dat['brain_area']==r]\n",
        "    ROI_nn.append(roi_nn)\n",
        "    if roi_nn.shape[0] >0:\n",
        "      indx_counter += roi_nn.shape[0] \n",
        "      nn_per_area[r] = indx_counter -1 # subtract one to get correct Python indx\n",
        "       \n",
        "      #nn_per_area.append((r,indx_counter)) # store n of neurons in that sub area # use this for list instead of dict\n",
        "      \n",
        "\n",
        "  # Return activations from same 'macro' area in the same tensor dimension as well as return   \n",
        "  return np.concatenate(ROI_nn,axis=0), nn_per_area \n"
      ],
      "metadata": {
        "id": "0VBdPgyvda53"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert signal into frequency by averaging activity across n trials\n",
        "\n",
        "def no_overlap_frequency(alldat,n_aver_trials=5, time_bin = 0.01):\n",
        "\n",
        "  n_trl = alldat.shape[1]\n",
        "  n_new_trl = n_trl  // n_aver_trials\n",
        "\n",
        "  \n",
        "  \n",
        "  # Ensure that if you have a big remainder at the end \n",
        "  # you compute the mean of that remainder and add it as a final trial\n",
        "  \n",
        "  remainder =  n_trl - n_new_trl * n_aver_trials\n",
        "  \n",
        "  if  remainder >= n_aver_trials-2:\n",
        "    frequency_spk = np.zeros((alldat.shape[0],n_new_trl + 1,alldat.shape[2]))\n",
        "    sub_data = alldat[:,n_new_trl:]\n",
        "    frequency_spk[:,-1:] = np.mean(sub_data, axis= 1, keepdims=True) / time_bin\n",
        "  \n",
        "  else:\n",
        "    frequency_spk = np.zeros((alldat.shape[0],n_new_trl,alldat.shape[2])) \n",
        "\n",
        "  indexes = np.arange(0,n_trl ,n_aver_trials)\n",
        "\n",
        "\n",
        "  \n",
        "  t = 0\n",
        "  for i in indexes[:-1]:\n",
        "      sub_data = alldat[:,i:indexes[t+1]]\n",
        "      frequency_spk[:,t:t+1] = np.mean(sub_data, axis= 1, keepdims=True) / time_bin\n",
        "      t+=1\n",
        "      \n",
        "  \n",
        "\n",
        "  return frequency_spk\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dLlIlgMhlJsV"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sliding averaged window:\n",
        "\n",
        "def overlapping_frequency(alldat,n_overlapping_trials=100, time_bin = 0.01):\n",
        "  \n",
        "  area = alldat\n",
        "\n",
        "  window_len = n_overlapping_trials # in trials\n",
        "\n",
        "  last_step  = area.shape[1] - window_len\n",
        "  step_range = (np.arange(0, last_step, 1))\n",
        "\n",
        "  # init\n",
        "  spike_rate = np.zeros((area.shape[0], last_step, area.shape[2]))\n",
        "\n",
        "\n",
        "\n",
        "  # loop over neurons\n",
        "  for n in range(0, area.shape[0]):\n",
        "  \n",
        "    # slide trial window\n",
        "    for p in step_range:\n",
        "      \n",
        "      # compute average and fill spike rate matrix\n",
        "      for x in range(0, area.shape[1], window_len):\n",
        "        trial_avg = area[n, np.arange(p, p+window_len, 1), :].mean(axis=0)\n",
        "        trial_avg = trial_avg/time_bin # time average\n",
        "        spike_rate[n,p,:] = trial_avg \n",
        "\n",
        "  return spike_rate\n"
      ],
      "metadata": {
        "id": "MDanUJD1hGPP"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start extracing and preparing the data"
      ],
      "metadata": {
        "id": "6w0QnccVM2-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise some useful variables for data extraction/organisation\n",
        "\n",
        "ROI_n = 0\n",
        "session_id = 34\n",
        "time_bin = 0.01 # DON'T CHANGE, given by the experiment\n",
        "\n",
        "overlapping_trials = False\n",
        "n_overlapping_tr = 100\n",
        "\n",
        "n_nonOverlap_tr = 20\n",
        "\n",
        "subtract_baseline = True\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VmgVj2WAM7JP"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data:\n",
        "r_data, dict_indx = data_org(alldat, session_id = session_id, ROI_number = ROI_n)\n",
        "\n",
        "\n",
        "\n",
        "#Inspect data indexes \n",
        "print(dict_indx)\n",
        "print(r_data.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf2HSVg1s8wU",
        "outputId": "79f9c70c-cb3b-4fb8-a7ed-6c20a5c5f461"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'VISam': 74}\n",
            "(75, 311, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo skipping\n",
        "\n",
        "# Plot spikes for overlapping trials\n",
        "\n",
        "spike_rate = overlapping_frequency(r_data,n_overlapping_trials=n_overlapping_tr, time_bin = time_bin)\n",
        "ex_unit  = 30\n",
        "plt.imshow(spike_rate[ex_unit, :, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy1alFZAL4_m",
        "outputId": "0416e11b-b6ef-4191-96f8-080bd3ac9d02"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skipping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo skipping\n",
        "\n",
        "# Plot spikes for NON-overlapping trials\n",
        "\n",
        "no_overlap_data = no_overlap_frequency(r_data,n_aver_trials=n_nonOverlap_tr,time_bin = time_bin)\n",
        "\n",
        "\n",
        "fig, (ax1,ax2) = plt.subplots(1,2)\n",
        "\n",
        "ax1.imshow(no_overlap_data[ex_unit, :, :])\n",
        "\n",
        "\n",
        "ax2.imshow(r_data[ex_unit, :, :])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#ax.set_ylim(0, 2)\n"
      ],
      "metadata": {
        "id": "YkmNnjzpjtOq",
        "outputId": "9a149c3f-35e6-4d69-ad15-2e9ac37cbeb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skipping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare data for training the RNN (i.e. select a (sub) area for analysis and split neurons in two groups)**"
      ],
      "metadata": {
        "id": "4Klwjcnv6Bgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide if want to use overlapping trails to compute frequency or not\n",
        "\n",
        "if overlapping_trials == True:\n",
        "  spike_rate = overlapping_frequency(r_data,n_overlapping_trials=n_overlapping_tr, time_bin = time_bin)\n",
        "  print(\"Overlapping data\")\n",
        "else:\n",
        "  spike_rate = no_overlap_frequency(r_data,n_aver_trials=n_nonOverlap_tr,time_bin =time_bin)\n",
        "  print(\"No overlapping data\") "
      ],
      "metadata": {
        "id": "PWSmbDz_orJw",
        "outputId": "18960b1d-c3d0-49f5-854a-6b47218b7f60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No overlapping data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove baseline and normalise data trhough baseline\n",
        "baseline_end = 50\n",
        "baseline_mean = spike_rate[:,:,0:baseline_end].mean(axis=2, keepdims=True) \n",
        "\n",
        "r_data_2 = spike_rate[:,:,baseline_end:]\n",
        "\n",
        "# Subtract baseline from signal to improve data\n",
        "if subtract_baseline:\n",
        "\n",
        "  r_data_2 -= baseline_mean\n",
        "  r_data_2 = np.maximum(0,r_data_2)\n",
        "\n",
        "\n",
        "# Extract region with most neurons\n",
        "indexes = list(dict_indx.values())\n",
        "roi_indx = np.argmax(indexes)\n",
        "\n",
        "\n",
        "\n",
        "# Create indexes to divide data in training and testing:\n",
        "if len(indexes) >1:\n",
        "  init_indx = indexes[roi_indx-1] # take index marking the end of previous area\n",
        "  final_indx = indexes[roi_indx]\n",
        "\n",
        "else:\n",
        "    init_indx = 0 # take index marking the end of previous area\n",
        "    final_indx = indexes[roi_indx]\n",
        "\n",
        "\n",
        "mid_indx = int((final_indx-init_indx)/2) + init_indx # need to add back initial indx as we are not starting from the beginning\n",
        "\n",
        "\n",
        "training_nn = r_data_2[init_indx:mid_indx]\n",
        "testing_nn = r_data_2[mid_indx:final_indx]\n"
      ],
      "metadata": {
        "id": "TCP3geOKvQmI"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(init_indx,mid_indx,final_indx)\n",
        "print(training_nn.shape,testing_nn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSiGzDv3ty5j",
        "outputId": "a4e9ee0e-612e-436c-d10d-5a81b184b83d"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 37 74\n",
            "(37, 15, 200) (37, 15, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **============ Data Analysis ============**"
      ],
      "metadata": {
        "id": "y2Uc5IF7kwpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "mSO48SXHp478"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the RNN** "
      ],
      "metadata": {
        "id": "C2_ysPKylbjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  \n",
        "  def __init__(self, ncomp, NN1, NN2,lr = .005,loss_type= 2, bidi=True, batch_size=30):\n",
        "    \n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    # play with some of the options in the RNN!\n",
        "    self.rnn = nn.RNN(NN1, ncomp, num_layers = 1, dropout = 0,\n",
        "                      bidirectional = bidi, nonlinearity = 'relu')\n",
        "    self.fc = nn.Linear(ncomp, NN2)\n",
        "\n",
        "    self.ncomp = ncomp\n",
        "    \n",
        "    self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "    self.loss = nn.MSELoss()\n",
        "\n",
        "    self.loss_type = loss_type\n",
        "\n",
        "  \n",
        "  \n",
        "  def forward(self, x):\n",
        "\n",
        "    y = self.rnn(x)[0]\n",
        "\n",
        "    if self.rnn.bidirectional:\n",
        "      # if the rnn is bidirectional, it concatenates the activations from the forward and backward pass\n",
        "      # we want to add them instead, so as to enforce the latents to match between the forward and backward pass\n",
        "      q = (y[:, :, :self.ncomp] + y[:, :, self.ncomp:])/2\n",
        "    else:\n",
        "      q = y\n",
        "\n",
        "    # the softplus function is just like a relu but it's smoothed out so we can't predict 0\n",
        "    # if we predict 0 and there was a spike, that's an instant Inf in the Poisson log-likelihood which leads to failure\n",
        "    z = F.softplus(self.fc(q), 10)\n",
        "\n",
        "    return z, q\n",
        "  \n",
        "  def Poisson_loss_update(self,lam, spk):\n",
        "\n",
        "    loss = torch.mean(lam - spk * torch.log(lam))\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "  def train(self,input,target,niter = 1000):\n",
        "\n",
        "      # special thing:  we initialize the biases of the last layer in the neural network\n",
        "      # we set them as the mean firing rates of the neurons.\n",
        "      # this should make the initial predictions close to the mean, because the latents don't contribute much\n",
        "      self.fc.bias.data[:] = input.mean((0,1))\n",
        "\n",
        "      max_n_trials = input.shape[1]\n",
        "\n",
        "      \n",
        "      for k in range(niter):\n",
        "          batch_indx = torch.randint(0, max_n_trials, (self.batch_size,))\n",
        "          x = input[:,batch_indx,:]\n",
        "          # the network outputs the single-neuron prediction and the latents\n",
        "          y_hat, h = self(x)\n",
        "\n",
        "          y_tar = target[:,batch_indx,:]\n",
        "      \n",
        "          if self.loss_type == 1:\n",
        "              # train the network with Poisson log-likelihood cost\n",
        "              loss = self.Poisson_loss_update(y_hat,y_tar)\n",
        "          \n",
        "          elif self.loss_type == 2:\n",
        "              # train the network with L2 cost\n",
        "              loss = self.loss(y_hat,y_tar)\n",
        "          \n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "          self.optimizer.zero_grad()\n",
        "\n",
        "          if k % 100 == 0:\n",
        "            print(f'iteration {k}, cost {loss.item():.4f}')\n",
        "    \n"
      ],
      "metadata": {
        "id": "-zKfE-R7k0BF"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise \n",
        "\n",
        "n_iterations = 5000\n",
        "ln_rate = 0.0005\n",
        "loss_type = 2 # 1: Poisson, 2: L2\n",
        "ncomp = 10\n",
        "deterministic = True\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "4ds6C80JxzaZ"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define RNN for training\n",
        "\n",
        "if deterministic:\n",
        "   torch.manual_seed(0)\n",
        "\n",
        "# Convert data to torch.tensor():\n",
        "#print(np.mean(np.equal(training_nn,testing_nn)))\n",
        "\n",
        "tr_nn  = torch.tensor(training_nn, device=device).float()\n",
        "ts_nn = torch.tensor(testing_nn, device=device).float()\n",
        "\n",
        "# Put them in the right shape for the RNN\n",
        "tr_nn = torch.permute(tr_nn ,(2,1,0))\n",
        "ts_nn = torch.permute(ts_nn,(2,1,0))\n",
        "\n",
        "NN1 = tr_nn.shape[-1]\n",
        "NN2 = ts_nn.shape[-1]\n",
        "\n",
        "\n",
        "\n",
        "net = Net(ncomp, NN1, NN2,lr = ln_rate, loss_type= loss_type,bidi = True).to(device) # .0005\n",
        "\n",
        "net.train(tr_nn,ts_nn, niter = n_iterations)"
      ],
      "metadata": {
        "id": "w7Xrxbyppg9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fdd8541-1c12-4df4-ca5f-76eac35f5045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0, cost 43.6182\n",
            "iteration 100, cost 33.7987\n",
            "iteration 200, cost 26.6678\n",
            "iteration 300, cost 23.9128\n",
            "iteration 400, cost 22.6683\n",
            "iteration 500, cost 22.6821\n",
            "iteration 600, cost 22.4705\n",
            "iteration 700, cost 21.7679\n",
            "iteration 800, cost 21.6507\n",
            "iteration 900, cost 20.6046\n",
            "iteration 1000, cost 21.3366\n",
            "iteration 1100, cost 21.0719\n",
            "iteration 1200, cost 20.2025\n",
            "iteration 1300, cost 20.0106\n",
            "iteration 1400, cost 20.5176\n",
            "iteration 1500, cost 19.4314\n",
            "iteration 1600, cost 19.7150\n",
            "iteration 1700, cost 19.4728\n",
            "iteration 1800, cost 19.7636\n",
            "iteration 1900, cost 20.0562\n",
            "iteration 2000, cost 19.8665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_hat, _ = net(tr_nn)\n",
        "# x = torch.poisson(y_hat)\n",
        "# ts_nn_numpy = ts_nn\n",
        "\n",
        "# print(torch.sum(torch.eq(x,ts_nn_numpy))/torch.numel(x))\n",
        "\n",
        "# print(x.shape)\n",
        "# print(ts_nn_numpy.shape)\n"
      ],
      "metadata": {
        "id": "WGdaJWS7mPfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat, _ = net(tr_nn)\n",
        "#x = np.random.poisson(y_hat.detach().cpu().numpy())\n",
        "\n",
        "x = y_hat.detach().cpu().numpy()\n",
        "\n",
        "x = x / np.max(x, axis=0)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "\n",
        "\n",
        "rpred = x\n",
        "\n",
        "ts_nn_numpy = ts_nn.detach().cpu().numpy()\n",
        "ts_nn_numpy = ts_nn_numpy / np.max(ts_nn_numpy, axis=0)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "nn = 10\n",
        "trial_n = 0\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ts_nn_numpy[:,trial_n, nn])\n",
        "plt.plot(rpred[:,trial_n, nn])\n",
        "#plt.plot(-.5 + x[:, nn, 0]/4)\n",
        "\n",
        "plt.legend(['rates (true)', 'rates (predicted)', 'spikes'])\n",
        "plt.title(f'Neuron {nn}')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GJjhHherdIDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat, _ = net(tr_nn)\n",
        "\n",
        "rpred = y_hat.detach().cpu().numpy()\n",
        "\n",
        "ts_nn_numpy = ts_nn.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "nn = 50\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ts_nn_numpy[:,nn, 0])\n",
        "plt.plot(rpred[:,nn, 0])\n",
        "#plt.plot(-.5 + x[:, nn, 0]/4)\n",
        "\n",
        "plt.legend(['rates (true)', 'rates (predicted)', 'spikes'])\n",
        "plt.title(f'Neuron {nn}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KJ6MqmfUKP-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot latent space\n",
        "_, h = net(tr_nn)\n",
        "\n",
        "hcpu = h.detach().cpu().numpy()\n",
        "plt.figure(figsize=(20, 4))\n",
        "plt.subplot(121)\n",
        "\n",
        "print(hcpu.shape)\n",
        "\n",
        "\n",
        "for c in np.arange(0,10):\n",
        "\n",
        "  plt.plot(hcpu[:, 0, c], label = c);\n",
        "\n",
        "\n",
        "plt.legend(loc='best', bbox_to_anchor=(0.5, 0., 0.5, 0.5))\n",
        "plt.title('All latents on trial 0')\n",
        "plt.xlim(0,60)\n",
        "\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(hcpu[:, :, 2]);\n",
        "plt.title('All trials for latent 0')\n",
        "plt.xlim(0,60)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LWGDY9aa5saH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 6))\n",
        "plt.imshow(tr_nn.cpu().numpy()[:, 0, :].T, cmap='gray_r', vmax = 3, vmin=0, aspect='auto')\n",
        "plt.xlabel('Time (ms)')\n",
        "plt.ylabel('Cell #')\n",
        "plt.colorbar(orientation='vertical', label='# Spikes in 0.01 s time bin')\n",
        "plt.title('Example trial')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "__iUgpPrvSUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5uCCXjx85sNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extra**"
      ],
      "metadata": {
        "id": "ZcDRCgYC5syk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Select session from which you want to extract the data\n",
        "# dat = alldat[11]\n",
        "\n",
        "# # Define one \"macro\" region of interest from which you want to extact the data, e.g. 0:\"vis ctx\", 1:\"thal\", etc. \n",
        "# ROI_number = 0 # take visual areas\n",
        "# ROI = brain_groups[ROI_number]\n",
        "\n",
        "# ROI_nn = []\n",
        "# nn_per_area = [] # store the number of neurons in each sub area of a \"macro area\" for indexing\n",
        "\n",
        "# nn_per_area = dict()\n",
        "\n",
        "# indx_counter =0\n",
        "# # Extract spikes from ROI:\n",
        "# for r in ROI:\n",
        "#   roi_nn = dat['spks'][dat['brain_area']==r]\n",
        "#   ROI_nn.append(roi_nn)\n",
        "#   if roi_nn.shape[0] >0:\n",
        "#     indx_counter += roi_nn.shape[0] \n",
        "#     #nn_per_area.append((r,indx_counter)) # store n of neurons in that sub area\n",
        "#     nn_per_area[r] = indx_counter\n",
        "\n",
        "# # Put activations from same 'macro' area in the same tensor dimension  \n",
        "# ROI_nn = np.concatenate(ROI_nn,axis=0)\n",
        "\n",
        "# print(ROI_nn.shape)\n",
        "# print(nn_per_area)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1uB7sjp8BjtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CA3_nn = dat['spks'][dat['brain_area']=='CA3'][0].mean(axis=0)\n",
        "# print(CA3_nn.shape)\n",
        "\n",
        "\n",
        "# nn_number = np.arange(1, len(CA3_nn)+1)\n",
        "\n",
        "# plt.plot(nn_number,CA3_nn)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "6wbb8gHj5vv9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of load_steinmetz_decisions",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}